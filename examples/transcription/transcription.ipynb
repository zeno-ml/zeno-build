{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "import os\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import zeno_client\n",
    "import dotenv\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"speech_accent_archive.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data\"] = \"https://zenoml.s3.amazonaws.com/accents/\" + df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = zeno_client.ZenoClient(os.environ.get(\"ZENO_API_KEY\"))\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"Transcription Whisper Distil\", \n",
    "    view=\"audio-transcription\",\n",
    "    description=\"Test of audio transcription\",\n",
    "    metrics=[\n",
    "        zeno_client.ZenoMetric(name=\"avg wer\", type=\"mean\", columns=[\"wer\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.upload_dataset(df, id_column=\"id\", data_column=\"data\", label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"tiny.en\", \"base.en\", \"medium.en\", \"large\", \"distil-medium.en\", \"distil-large-v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "\n",
    "df_systems = []\n",
    "for model_name in models:\n",
    "    try:\n",
    "        df_system = pd.read_parquet(f\"cache/{model_name}.parquet\")\n",
    "    except:\n",
    "        df_system = df[[\"id\", \"data\", \"label\"]].copy()\n",
    "\n",
    "        if \"distil\" in model_name:\n",
    "            model_id = \"distil-whisper/\" + model_name\n",
    "            model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "                model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "            )\n",
    "            model.to(device)\n",
    "            processor = AutoProcessor.from_pretrained(model_id)\n",
    "            model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "                model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "            )\n",
    "            model.to(device)\n",
    "\n",
    "            processor = AutoProcessor.from_pretrained(model_id)\n",
    "            pipe = pipeline(\n",
    "                \"automatic-speech-recognition\",\n",
    "                model=model,\n",
    "                tokenizer=processor.tokenizer,\n",
    "                feature_extractor=processor.feature_extractor,\n",
    "                max_new_tokens=128,\n",
    "                torch_dtype=torch_dtype,\n",
    "                device=device,\n",
    "            )\n",
    "            df_system[\"output\"] = df_system[\"data\"].apply(lambda x: pipe(x)['text'])\n",
    "            pass\n",
    "        else:\n",
    "            whisper_model = whisper.load_model(model_name)\n",
    "            df_system[\"output\"] = df_system[\"data\"].apply(lambda x: whisper_model.transcribe(x)[\"text\"])\n",
    "\n",
    "        df_system[\"wer\"] = df_system.apply(lambda x: wer(x[\"label\"], x[\"output\"]), axis=1)\n",
    "        df_system.to_parquet(f\"cache/{model_name}.parquet\", index=False)\n",
    "    df_systems.append(df_system) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_system in enumerate(df_systems):\n",
    "    project.upload_system(df_system[[\"id\", \"output\", \"wer\"]], name=models[i], id_column=\"id\", output_column=\"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
